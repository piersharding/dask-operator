apiVersion: analytics.piersharding.com/v1
kind: DaskJob
metadata:
  name: daskjob-app1
spec:
  cluster: app1
  image: jupyter/scipy-notebook:latest
  imagePullPolicy: IfNotPresent
  env:
    - name: PYTHONPATH
      value: /pylibs:/arl
    - name: ARL
      value: /arl
    - name: ARL_DASK_SCHEDULER
      value: dask-scheduler-app1:8786
  volumes:
    - hostPath:
        path: /home/piers/git/private/algorithm-reference-library
        type: DirectoryOrCreate
      name: arl
    - name: pylibs
      persistentVolumeClaim:
        claimName: pylibs
  volumeMounts:
    - mountPath: /arl
      readOnly: false
      name: arl
    - mountPath: "/pylibs"
      name: pylibs

  script: |
    {
    "cells": [
      {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Pipeline processing using arlexecute workflows.\n",
        "\n",
        "This notebook demonstrates the continuum imaging and ICAL pipelines. These are based on ARL functions wrapped up as SDP workflows using the arlexecute class."
      ]
      },
      {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
        "end_time": "2019-04-03T09:21:05.704764Z",
        "start_time": "2019-04-03T09:21:04.076102Z"
        }
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "sys.path.append(os.path.join('..', '..'))\n",
        "\n",
        "from data_models.parameters import arl_path\n",
        "\n",
        "results_dir = arl_path('test_results')\n",
        "\n",
        "from matplotlib import pylab\n",
        "\n",
        "pylab.rcParams['figure.figsize'] = (12.0, 12.0)\n",
        "pylab.rcParams['image.cmap'] = 'rainbow'\n",
        "\n",
        "import numpy\n",
        "\n",
        "from astropy.coordinates import SkyCoord\n",
        "from astropy import units as u\n",
        "from astropy.wcs.utils import pixel_to_skycoord\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from data_models.polarisation import PolarisationFrame\n",
        "\n",
        "from wrappers.serial.calibration.calibration import solve_gaintable\n",
        "from wrappers.serial.calibration.operations import apply_gaintable\n",
        "from wrappers.serial.calibration.calibration_control import create_calibration_controls\n",
        "from wrappers.serial.visibility.base import create_blockvisibility\n",
        "from wrappers.serial.skycomponent.operations import create_skycomponent\n",
        "from wrappers.serial.image.deconvolution import deconvolve_cube\n",
        "from wrappers.serial.image.operations import show_image, export_image_to_fits, qa_image\n",
        "from wrappers.serial.visibility.iterators import vis_timeslice_iter\n",
        "from wrappers.serial.simulation.testing_support import create_low_test_image_from_gleam\n",
        "from wrappers.serial.simulation.configurations import create_named_configuration\n",
        "from wrappers.serial.imaging.base import predict_2d, create_image_from_visibility, advise_wide_field\n",
        "from wrappers.serial.visibility.coalesce import convert_blockvisibility_to_visibility\n",
        "\n",
        "from workflows.arlexecute.imaging.imaging_arlexecute import invert_list_arlexecute_workflow, \\\n",
        "    predict_list_arlexecute_workflow, deconvolve_list_arlexecute_workflow\n",
        "from workflows.arlexecute.simulation.simulation_arlexecute import simulate_list_arlexecute_workflow, \\\n",
        "    corrupt_list_arlexecute_workflow\n",
        "from workflows.arlexecute.pipelines.pipeline_arlexecute import continuum_imaging_list_arlexecute_workflow, \\\n",
        "    ical_list_arlexecute_workflow\n",
        "\n",
        "from wrappers.arlexecute.execution_support.arlexecute import arlexecute\n",
        "\n",
        "import pprint\n",
        "\n",
        "pp = pprint.PrettyPrinter()\n",
        "\n",
        "import logging\n",
        "\n",
        "def init_logging():\n",
        "    log = logging.getLogger()\n",
        "    logging.basicConfig(filename='%s/imaging-pipeline.log' % results_dir,\n",
        "                        filemode='a',\n",
        "                        format='%(asctime)s,%(msecs)d %(name)s %(levelname)s %(message)s',\n",
        "                        datefmt='%H:%M:%S',\n",
        "                        level=logging.INFO)\n",
        "log = logging.getLogger()\n",
        "logging.info(\"Starting imaging-pipeline\")\n"
      ]
      },
      {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will use dask"
      ]
      },
      {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
        "end_time": "2019-04-03T09:21:08.307073Z",
        "start_time": "2019-04-03T09:21:05.707738Z"
        }
      },
      "outputs": [],
      "source": [
        "print(os.environ)"
      ]
      },
      {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.environ['PYTHONPATH']\n",
        "import astropy"
      ]
      },
      {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
        "end_time": "2019-04-03T09:21:08.307073Z",
        "start_time": "2019-04-03T09:21:05.707738Z"
        }
      },
      "outputs": [],
      "source": [
        "arlexecute.set_client(use_dask=True, address=os.environ['DASK_SCHEDULER'])\n",
        "arlexecute.run(init_logging)"
      ]
      },
      {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "arlexecute.client"
      ]
      },
      {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
        "end_time": "2019-04-03T09:21:08.312929Z",
        "start_time": "2019-04-03T09:21:08.309064Z"
        }
      },
      "outputs": [],
      "source": [
        "pylab.rcParams['figure.figsize'] = (12.0, 12.0)\n",
        "pylab.rcParams['image.cmap'] = 'Greys'"
      ]
      },
      {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We create a graph to make the visibility. The parameter rmax determines the distance of the furthest antenna/stations used. All over parameters are determined from this number."
      ]
      },
      {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
        "end_time": "2019-04-03T09:21:09.936984Z",
        "start_time": "2019-04-03T09:21:08.316673Z"
        }
      },
      "outputs": [],
      "source": [
        "nfreqwin=7\n",
        "ntimes=5\n",
        "rmax=300.0\n",
        "frequency=numpy.linspace(1e8,1.2e8,nfreqwin)\n",
        "channel_bandwidth=numpy.array(nfreqwin*[frequency[1]-frequency[0]])\n",
        "times = numpy.linspace(-numpy.pi/3.0, numpy.pi/3.0, ntimes)\n",
        "phasecentre=SkyCoord(ra=+30.0 * u.deg, dec=-60.0 * u.deg, frame='icrs', equinox='J2000')\n",
        "\n",
        "bvis_list=simulate_list_arlexecute_workflow('LOWBD2',\n",
        "                                         frequency=frequency, \n",
        "                                         channel_bandwidth=channel_bandwidth,\n",
        "                                         times=times,\n",
        "                                         phasecentre=phasecentre,\n",
        "                                         order='frequency',\n",
        "                                        rmax=rmax, format='blockvis')\n",
        "vis_list = [arlexecute.execute(convert_blockvisibility_to_visibility)(bv) for bv in bvis_list]\n",
        "\n",
        "print('%d elements in vis_list' % len(vis_list))\n",
        "log.info('About to make visibility')\n",
        "vis_list = arlexecute.compute(vis_list, sync=True)"
      ]
      },
      {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
        "end_time": "2019-04-03T09:21:09.955729Z",
        "start_time": "2019-04-03T09:21:09.942306Z"
        }
      },
      "outputs": [],
      "source": [
        "wprojection_planes=1\n",
        "advice_low=advise_wide_field(vis_list[0], guard_band_image=8.0, delA=0.02,\n",
        "                             wprojection_planes=wprojection_planes)\n",
        "\n",
        "advice_high=advise_wide_field(vis_list[-1], guard_band_image=8.0, delA=0.02,\n",
        "                              wprojection_planes=wprojection_planes)\n",
        "\n",
        "vis_slices = advice_low['vis_slices']\n",
        "npixel=advice_high['npixels2']\n",
        "cellsize=min(advice_low['cellsize'], advice_high['cellsize'])"
      ]
      },
      {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now make a graph to fill with a model drawn from GLEAM "
      ]
      },
      {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
        "end_time": "2019-04-03T09:21:15.129629Z",
        "start_time": "2019-04-03T09:21:09.958022Z"
        }
      },
      "outputs": [],
      "source": [
        "gleam_model = [arlexecute.execute(create_low_test_image_from_gleam)(npixel=npixel,\n",
        "                                                               frequency=[frequency[f]],\n",
        "                                                               channel_bandwidth=[channel_bandwidth[f]],\n",
        "                                                               cellsize=cellsize,\n",
        "                                                               phasecentre=phasecentre,\n",
        "                                                               polarisation_frame=PolarisationFrame(\"stokesI\"),\n",
        "                                                               flux_limit=1.0,\n",
        "                                                               applybeam=True)\n",
        "                     for f, freq in enumerate(frequency)]\n",
        "log.info('About to make GLEAM model')\n",
        "gleam_model = arlexecute.compute(gleam_model, sync=True)\n",
        "future_gleam_model = arlexecute.scatter(gleam_model)"
      ]
      },
      {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
        "end_time": "2019-04-03T09:21:32.204717Z",
        "start_time": "2019-04-03T09:21:15.132705Z"
        }
      },
      "outputs": [],
      "source": [
        "log.info('About to run predict to get predicted visibility')\n",
        "future_vis_graph = arlexecute.scatter(vis_list)\n",
        "predicted_vislist = predict_list_arlexecute_workflow(future_vis_graph, gleam_model,  \n",
        "                                                context='wstack', vis_slices=vis_slices)\n",
        "predicted_vislist = arlexecute.compute(predicted_vislist, sync=True)\n",
        "corrupted_vislist = corrupt_list_arlexecute_workflow(predicted_vislist, phase_error=1.0)\n",
        "log.info('About to run corrupt to get corrupted visibility')\n",
        "corrupted_vislist =  arlexecute.compute(corrupted_vislist, sync=True)\n",
        "future_predicted_vislist=arlexecute.scatter(predicted_vislist)"
      ]
      },
      {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Get the LSM. This is currently blank."
      ]
      },
      {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
        "end_time": "2019-04-03T09:21:32.213530Z",
        "start_time": "2019-04-03T09:21:32.206249Z"
        }
      },
      "outputs": [],
      "source": [
        "model_list = [arlexecute.execute(create_image_from_visibility)(vis_list[f],\n",
        "                                                     npixel=npixel,\n",
        "                                                     frequency=[frequency[f]],\n",
        "                                                     channel_bandwidth=[channel_bandwidth[f]],\n",
        "                                                     cellsize=cellsize,\n",
        "                                                     phasecentre=phasecentre,\n",
        "                                                     polarisation_frame=PolarisationFrame(\"stokesI\"))\n",
        "               for f, freq in enumerate(frequency)]"
      ]
      },
      {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
        "end_time": "2019-04-03T09:21:32.325468Z",
        "start_time": "2019-04-03T09:21:32.216314Z"
        }
      },
      "outputs": [],
      "source": [
        "dirty_list = invert_list_arlexecute_workflow(future_predicted_vislist, model_list, \n",
        "                                  context='wstack',\n",
        "                                  vis_slices=vis_slices, dopsf=False)\n",
        "psf_list = invert_list_arlexecute_workflow(future_predicted_vislist, model_list, \n",
        "                                context='wstack',\n",
        "                                vis_slices=vis_slices, dopsf=True)"
      ]
      },
      {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create and execute graphs to make the dirty image and PSF"
      ]
      },
      {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
        "end_time": "2019-04-03T09:21:53.835098Z",
        "start_time": "2019-04-03T09:21:32.327832Z"
        }
      },
      "outputs": [],
      "source": [
        "log.info('About to run invert to get dirty image')\n",
        "\n",
        "dirty_list =  arlexecute.compute(dirty_list, sync=True)\n",
        "dirty = dirty_list[0][0]\n",
        "show_image(dirty, cm='Greys', vmax=1.0, vmin=-0.1)\n",
        "plt.show()\n",
        "\n",
        "log.info('About to run invert to get PSF')\n",
        "\n",
        "\n",
        "psf_list =  arlexecute.compute(psf_list, sync=True)\n",
        "psf = psf_list[0][0]\n",
        "show_image(psf, cm='Greys', vmax=0.1, vmin=-0.01)\n",
        "plt.show()"
      ]
      },
      {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now deconvolve using msclean"
      ]
      },
      {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
        "end_time": "2019-04-03T09:31:47.754372Z",
        "start_time": "2019-04-03T09:31:44.664078Z"
        }
      },
      "outputs": [],
      "source": [
        "log.info('About to run deconvolve')\n",
        "\n",
        "deconvolve_list = \\\n",
        "    deconvolve_list_arlexecute_workflow(dirty_list, psf_list, model_imagelist=model_list, \n",
        "                            deconvolve_facets=8, deconvolve_overlap=16, deconvolve_taper='tukey',\n",
        "                            scales=[0, 3, 10],\n",
        "                            algorithm='msclean', niter=1000, \n",
        "                            fractional_threshold=0.1,\n",
        "                            threshold=0.1, gain=0.1, psf_support=64)\n",
        "    \n",
        "centre=nfreqwin // 2\n",
        "\n",
        "deconvolved = arlexecute.compute(deconvolve_list, sync=True)\n",
        "show_image(deconvolved[centre], cm='Greys', vmax=0.1, vmin=-0.01)\n",
        "plt.show()"
      ]
      },
      {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
        "end_time": "2019-04-03T09:22:00.925569Z",
        "start_time": "2019-04-03T09:21:58.762857Z"
        }
      },
      "outputs": [],
      "source": [
        "continuum_imaging_list = \\\n",
        "    continuum_imaging_list_arlexecute_workflow(future_predicted_vislist, \n",
        "                                            model_imagelist=model_list, \n",
        "                                            context='wstack', vis_slices=vis_slices, \n",
        "                                            scales=[0, 3, 10], algorithm='mmclean', \n",
        "                                            nmoment=3, niter=1000, \n",
        "                                            fractional_threshold=0.1,\n",
        "                                            threshold=0.1, nmajor=5, gain=0.25,\n",
        "                                            deconvolve_facets = 8, deconvolve_overlap=16, \n",
        "                                            deconvolve_taper='tukey', psf_support=64)\n"
      ]
      },
      {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
        "end_time": "2019-04-03T09:30:34.043945Z",
        "start_time": "2019-04-03T09:30:31.377721Z"
        }
      },
      "outputs": [],
      "source": [
        "log.info('About to run continuum imaging')\n",
        "\n",
        "centre=nfreqwin // 2\n",
        "continuum_imaging_list=arlexecute.compute(continuum_imaging_list, sync=True)\n",
        "deconvolved = continuum_imaging_list[0][centre]\n",
        "residual = continuum_imaging_list[1][centre]\n",
        "restored = continuum_imaging_list[2][centre]\n",
        "\n",
        "f=show_image(deconvolved, title='Clean image - no selfcal', cm='Greys', \n",
        "             vmax=0.1, vmin=-0.01)\n",
        "print(qa_image(deconvolved, context='Clean image - no selfcal'))\n",
        "\n",
        "plt.show()\n",
        "\n",
        "f=show_image(restored, title='Restored clean image - no selfcal', \n",
        "             cm='Greys', vmax=1.0, vmin=-0.1)\n",
        "print(qa_image(restored, context='Restored clean image - no selfcal'))\n",
        "plt.show()\n",
        "export_image_to_fits(restored, '%s/imaging-dask_continuum_imaging_restored.fits' \n",
        "                     %(results_dir))\n",
        "\n",
        "f=show_image(residual[0], title='Residual clean image - no selfcal', cm='Greys', \n",
        "             vmax=0.1, vmin=-0.01)\n",
        "print(qa_image(residual[0], context='Residual clean image - no selfcal'))\n",
        "plt.show()\n",
        "export_image_to_fits(residual[0], '%s/imaging-dask_continuum_imaging_residual.fits' \n",
        "                     %(results_dir))"
      ]
      },
      {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
        "end_time": "2019-04-03T09:24:58.126655Z",
        "start_time": "2019-04-03T09:24:53.126648Z"
        }
      },
      "outputs": [],
      "source": [
        "for chan in range(nfreqwin):\n",
        "    residual = continuum_imaging_list[1][chan]\n",
        "    show_image(residual[0], title='Channel %d' % chan, cm='Greys', \n",
        "               vmax=0.1, vmin=-0.01)\n",
        "    plt.show()"
      ]
      },
      {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
      }
    ],
    "metadata": {
      "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
      },
      "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
      }
    },
    "nbformat": 4,
    "nbformat_minor": 2
    }

